![alt text](https://github.com/denisgaribovic/customer-churn-prediction/blob/main/Banner.png)

# ğŸ¤– Customer Churn Prediction

A **production-ready machine learning pipeline** designed to help financial institutions **identify customers at risk of leaving**. This project uses interpretable models and comprehensive feature engineering on historical banking data to support **data-driven retention strategies** and improve customer lifetime value.

---

## âœ¨ Highlights

- ğŸ“Š Built on a simulated banking customer dataset (~10,000 rows)  
- ğŸ” Explored churn drivers using interactive Plotly visualizations  
- âš™ï¸ Engineered features including dummy variables, scaling, and preprocessing  
- ğŸ¤– Compared Logistic Regression, Random Forest, and XGBoost models  
- ğŸ“ˆ Evaluated model performance with Accuracy, Precision, Recall, F1 Score, and ROC AUC  
- ğŸ§ª Demonstrated live prediction on new customer data  
- ğŸ”„ Reproducible and modular pipeline designed for easy scaling and deployment  

---

## ğŸ¯ Business Context

Customer acquisition costs are rising, making **retention and loyalty critical for sustainable growth**. Businesses across sectors need effective tools to **predict churn early and act proactively**.

This project simulates how a company can:  
- Analyze customer behavior and churn drivers  
- Build accurate and interpretable churn prediction models  
- Provide actionable insights to marketing and retention teams  

---

## ğŸ› ï¸ Project Workflow

### 1. ğŸ“ Data Loading & Preparation

- Loaded and cleaned a simulated bank customer dataset with ~10,000 records  
- Ensured data integrity and handled missing values  

### 2. ğŸ§­ Exploratory Data Analysis (EDA)

- Visualized key features and churn correlations using Plotly  
- Saved visualizations as PNGs for reporting and transparency  

### 3. ğŸ§± Feature Engineering

- Applied dummy encoding for categorical variables  
- Scaled numerical features where appropriate  
- Created meaningful derived features to boost model performance  

### 4. ğŸ¤– Modeling & Comparison

- Trained three models:  
  - Logistic Regression (baseline, interpretable)  
  - Random Forest (robust, nonlinear)  
  - XGBoost (state-of-the-art gradient boosting)   

### 5. ğŸ“ˆ Model Evaluation

- Evaluated using multiple metrics: Accuracy, Precision, Recall, F1 Score, ROC AUC  

### 6. ğŸ§ª Prediction Demonstration

- Showcased live predictions on new customer samples with interpretability explanations
